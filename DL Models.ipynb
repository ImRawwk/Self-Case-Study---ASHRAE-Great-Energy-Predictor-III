{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.13.1\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hims1/Ashrae\\1_eda.ipynb\n",
      "C:/Users/hims1/Ashrae\\Ashrae - Great Energy Predictor III.ipynb\n",
      "C:/Users/hims1/Ashrae\\Ashrae Final  GCP v2 Final - Great Energy Predictor III.ipynb\n",
      "C:/Users/hims1/Ashrae\\Ashrae Final  GCP v2- Great Energy Predictor III.ipynb\n",
      "C:/Users/hims1/Ashrae\\Ashrae Final - Great Energy Predictor III.ipynb\n",
      "C:/Users/hims1/Ashrae\\ashrae.png\n",
      "C:/Users/hims1/Ashrae\\building_metadata.csv\n",
      "C:/Users/hims1/Ashrae\\D2_pred.csv\n",
      "C:/Users/hims1/Ashrae\\final_xte.csv\n",
      "C:/Users/hims1/Ashrae\\sample_submission.csv\n",
      "C:/Users/hims1/Ashrae\\test.csv\n",
      "C:/Users/hims1/Ashrae\\test_pred.csv\n",
      "C:/Users/hims1/Ashrae\\train.csv\n",
      "C:/Users/hims1/Ashrae\\Untitled.ipynb\n",
      "C:/Users/hims1/Ashrae\\Untitled1.ipynb\n",
      "C:/Users/hims1/Ashrae\\Untitled2.ipynb\n",
      "C:/Users/hims1/Ashrae\\weather_test.csv\n",
      "C:/Users/hims1/Ashrae\\weather_train.csv\n",
      "C:/Users/hims1/Ashrae\\X_test.csv\n",
      "C:/Users/hims1/Ashrae\\X_train.csv\n",
      "C:/Users/hims1/Ashrae\\.ipynb_checkpoints\\1_eda-checkpoint.ipynb\n",
      "C:/Users/hims1/Ashrae\\.ipynb_checkpoints\\Ashrae - Great Energy Predictor III-checkpoint.ipynb\n",
      "C:/Users/hims1/Ashrae\\.ipynb_checkpoints\\Ashrae Final  GCP v2 Final - Great Energy Predictor III-checkpoint.ipynb\n",
      "C:/Users/hims1/Ashrae\\.ipynb_checkpoints\\Ashrae Final  GCP v2- Great Energy Predictor III-checkpoint.ipynb\n",
      "C:/Users/hims1/Ashrae\\.ipynb_checkpoints\\Ashrae Final - Great Energy Predictor III-checkpoint.ipynb\n",
      "C:/Users/hims1/Ashrae\\.ipynb_checkpoints\\Untitled-checkpoint.ipynb\n",
      "C:/Users/hims1/Ashrae\\.ipynb_checkpoints\\Untitled1-checkpoint.ipynb\n",
      "C:/Users/hims1/Ashrae\\.ipynb_checkpoints\\Untitled2-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('C:/Users/hims1/Ashrae'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dropout, Dense, Embedding, SpatialDropout1D, concatenate, BatchNormalization, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.losses import mean_squared_error as mse_loss\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Dropout\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Train & Test Set for fitting into the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv(\"C:/Users/hims1/Ashrae/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(x_train.columns[x_train.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.drop(x_test.columns[x_test.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log1p(x_train[\"meter_reading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = np.log1p(x_test[\"meter_reading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(columns=['meter_reading', 'meter_reading_log1p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.drop(columns=['meter_reading', 'meter_reading_log1p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_direction_max_lag72</th>\n",
       "      <th>wind_speed_max_lag72</th>\n",
       "      <th>wind_speed_min_lag72</th>\n",
       "      <th>wind_speed_std_lag72</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekend</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>log_square_feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50623</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5374</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5374</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97532</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81580</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter  site_id  primary_use  square_feet  air_temperature  \\\n",
       "0          105      0        1            0        50623              3.8   \n",
       "1          106      0        1            0         5374              3.8   \n",
       "2          106      3        1            0         5374              3.8   \n",
       "3          107      0        1            0        97532              3.8   \n",
       "4          108      0        1            0        81580              3.8   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "0             0.0              2.4                0.0              1021.0   \n",
       "1             0.0              2.4                0.0              1021.0   \n",
       "2             0.0              2.4                0.0              1021.0   \n",
       "3             0.0              2.4                0.0              1021.0   \n",
       "4             0.0              2.4                0.0              1021.0   \n",
       "\n",
       "   ...  wind_direction_max_lag72  wind_speed_max_lag72  wind_speed_min_lag72  \\\n",
       "0  ...                     240.0                   3.1                   3.1   \n",
       "1  ...                     240.0                   3.1                   3.1   \n",
       "2  ...                     240.0                   3.1                   3.1   \n",
       "3  ...                     240.0                   3.1                   3.1   \n",
       "4  ...                     240.0                   3.1                   3.1   \n",
       "\n",
       "   wind_speed_std_lag72  year  month  weekend  day  hour  log_square_feet  \n",
       "0                   0.0  2016      1        4    1     0           10.836  \n",
       "1                   0.0  2016      1        4    1     0            8.586  \n",
       "2                   0.0  2016      1        4    1     0            8.586  \n",
       "3                   0.0  2016      1        4    1     0           11.484  \n",
       "4                   0.0  2016      1        4    1     0           11.310  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 1 :-  Sequential Model with 2 Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size = 64\n",
    "Learning_rate = 0.0003\n",
    "Epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = Sequential()\n",
    "model_reg.add(Dense(256, kernel_initializer='glorot_normal', activation='relu', input_dim=40))\n",
    "model_reg.add(Dense(128, kernel_initializer='glorot_normal', activation='relu'))\n",
    "model_reg.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.adam(lr=Learning_rate)\n",
    "model_reg.compile(loss='mse', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 43,521\n",
      "Trainable params: 43,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1331391 samples, validate on 570597 samples\n",
      "Epoch 1/30\n",
      "1331391/1331391 [==============================] - 133s 100us/step - loss: 4.1136 - val_loss: 4.3162\n",
      "Epoch 2/30\n",
      "1331391/1331391 [==============================] - 132s 99us/step - loss: 3.6761 - val_loss: 3.5274\n",
      "Epoch 3/30\n",
      "1331391/1331391 [==============================] - 133s 100us/step - loss: 3.5903 - val_loss: 3.4059\n",
      "Epoch 4/30\n",
      "1331391/1331391 [==============================] - 129s 97us/step - loss: 3.5544 - val_loss: 3.3114\n",
      "Epoch 5/30\n",
      "1331391/1331391 [==============================] - 127s 95us/step - loss: 3.5271 - val_loss: 3.3373\n",
      "Epoch 6/30\n",
      "1331391/1331391 [==============================] - 123s 92us/step - loss: 3.4890 - val_loss: 3.3125\n",
      "Epoch 7/30\n",
      "1331391/1331391 [==============================] - 123s 93us/step - loss: 3.4544 - val_loss: 3.2510\n",
      "Epoch 8/30\n",
      "1331391/1331391 [==============================] - 124s 93us/step - loss: 3.4302 - val_loss: 3.4877\n",
      "Epoch 9/30\n",
      "1331391/1331391 [==============================] - 123s 93us/step - loss: 3.4192 - val_loss: 3.4096\n",
      "Epoch 10/30\n",
      "1331391/1331391 [==============================] - 123s 92us/step - loss: 3.3941 - val_loss: 3.3649\n",
      "Epoch 11/30\n",
      "1331391/1331391 [==============================] - 123s 92us/step - loss: 3.4047 - val_loss: 3.3560\n",
      "Epoch 12/30\n",
      "1331391/1331391 [==============================] - 123s 92us/step - loss: 3.3751 - val_loss: 3.2668\n",
      "Epoch 13/30\n",
      "1331391/1331391 [==============================] - 123s 93us/step - loss: 3.3497 - val_loss: 2.9598\n",
      "Epoch 14/30\n",
      "1331391/1331391 [==============================] - 131s 98us/step - loss: 3.3637 - val_loss: 3.2842\n",
      "Epoch 15/30\n",
      "1331391/1331391 [==============================] - 134s 100us/step - loss: 3.3366 - val_loss: 2.8867\n",
      "Epoch 16/30\n",
      "1331391/1331391 [==============================] - 124s 93us/step - loss: 3.2240 - val_loss: 3.3558\n",
      "Epoch 17/30\n",
      "1331391/1331391 [==============================] - 122s 91us/step - loss: 3.3861 - val_loss: 3.3677\n",
      "Epoch 18/30\n",
      "1331391/1331391 [==============================] - 121s 91us/step - loss: 3.3715 - val_loss: 3.1903\n",
      "Epoch 19/30\n",
      "1331391/1331391 [==============================] - 130s 98us/step - loss: 3.3478 - val_loss: 3.4124\n",
      "Epoch 20/30\n",
      "1331391/1331391 [==============================] - 128s 96us/step - loss: 3.3315 - val_loss: 3.0022\n",
      "Epoch 21/30\n",
      "1331391/1331391 [==============================] - 133s 100us/step - loss: 3.2765 - val_loss: 3.3126\n",
      "Epoch 22/30\n",
      "1331391/1331391 [==============================] - 140s 105us/step - loss: 3.2476 - val_loss: 3.3950\n",
      "Epoch 23/30\n",
      "1331391/1331391 [==============================] - 124s 93us/step - loss: 3.2555 - val_loss: 2.9877\n",
      "Epoch 24/30\n",
      "1331391/1331391 [==============================] - 119s 90us/step - loss: 3.2573 - val_loss: 3.3797\n",
      "Epoch 25/30\n",
      "1331391/1331391 [==============================] - 134s 101us/step - loss: 3.1582 - val_loss: 3.5505\n",
      "Epoch 26/30\n",
      "1331391/1331391 [==============================] - 122s 91us/step - loss: 3.1271 - val_loss: 3.1313\n",
      "Epoch 27/30\n",
      "1331391/1331391 [==============================] - 121s 91us/step - loss: 3.0591 - val_loss: 3.2510\n",
      "Epoch 28/30\n",
      "1331391/1331391 [==============================] - 129s 97us/step - loss: 3.0421 - val_loss: 3.4117\n",
      "Epoch 29/30\n",
      "1331391/1331391 [==============================] - 130s 98us/step - loss: 3.0255 - val_loss: 2.6715\n",
      "Epoch 30/30\n",
      "1331391/1331391 [==============================] - 139s 105us/step - loss: 2.9221 - val_loss: 2.5957\n"
     ]
    }
   ],
   "source": [
    "history = model_reg.fit(x_train, target,\n",
    "                    epochs=Epochs,\n",
    "                    verbose=1, \n",
    "                    validation_data=(x_test, target_test),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "''\"This is a scorer function for calaculating RMSLE\"''\n",
    "\n",
    "def rmsle_score(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSLE =  1.6063063324663285\n"
     ]
    }
   ],
   "source": [
    "print('Train RMSLE = ',rmsle_score(np.expm1(target) , np.expm1(model_reg.predict(x_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570597/570597 [==============================] - 9s 15us/step\n",
      "RMSLE of Test set is  1.6111324618429952\n"
     ]
    }
   ],
   "source": [
    "preds = np.expm1(model_reg.predict(x_test,batch_size = 64,verbose = 1))\n",
    "print('RMSLE of Test set is ',rmsle_score(np.expm1(target_test).values , preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 2  :-  Sequential Model with 6 Dense Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_input = x_train.shape[1] \n",
    "te_input = x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 512)               20992     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 200,129\n",
      "Trainable params: 198,113\n",
      "Non-trainable params: 2,016\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten, BatchNormalization\n",
    "\n",
    "\n",
    "# create the  network\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu',   input_dim=tr_input))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1331391 samples, validate on 570597 samples\n",
      "Epoch 1/60\n",
      "1331391/1331391 [==============================] - 10s 7us/step - loss: 6.2917 - val_loss: 3.8786TA: 1s \n",
      "Epoch 2/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 4.3589 - val_loss: 3.6000\n",
      "Epoch 3/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 4.0567 - val_loss: 3.6465\n",
      "Epoch 4/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.9569 - val_loss: 3.6188\n",
      "Epoch 5/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.9008 - val_loss: 3.5783\n",
      "Epoch 6/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.8707 - val_loss: 3.6389\n",
      "Epoch 7/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.8365 - val_loss: 3.5075\n",
      "Epoch 8/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.8112 - val_loss: 3.4478\n",
      "Epoch 9/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.7813 - val_loss: 3.5010\n",
      "Epoch 10/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.7567 - val_loss: 3.4687\n",
      "Epoch 11/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.7517 - val_loss: 3.5360\n",
      "Epoch 12/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.7369 - val_loss: 3.3880\n",
      "Epoch 13/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.7114 - val_loss: 3.5011\n",
      "Epoch 14/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.6927 - val_loss: 3.4543\n",
      "Epoch 15/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.6648 - val_loss: 3.4054\n",
      "Epoch 16/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.6469 - val_loss: 3.4209\n",
      "Epoch 17/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.6213 - val_loss: 3.4188\n",
      "Epoch 18/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.6466 - val_loss: 3.4418\n",
      "Epoch 19/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.6195 - val_loss: 3.5104\n",
      "Epoch 20/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.6029 - val_loss: 3.4096\n",
      "Epoch 21/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5838 - val_loss: 3.4709\n",
      "Epoch 22/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5573 - val_loss: 3.5657\n",
      "Epoch 23/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5351 - val_loss: 3.6698\n",
      "Epoch 24/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5418 - val_loss: 3.6444\n",
      "Epoch 25/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.4798 - val_loss: 3.3859\n",
      "Epoch 26/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5641 - val_loss: 3.4462\n",
      "Epoch 27/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5656 - val_loss: 3.3754\n",
      "Epoch 28/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5486 - val_loss: 3.3743\n",
      "Epoch 29/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5406 - val_loss: 3.4854\n",
      "Epoch 30/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5513 - val_loss: 3.4475\n",
      "Epoch 31/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5453 - val_loss: 3.4329\n",
      "Epoch 32/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5208 - val_loss: 3.4946\n",
      "Epoch 33/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.4923 - val_loss: 3.6035\n",
      "Epoch 34/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5281 - val_loss: 3.5090\n",
      "Epoch 35/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.4722 - val_loss: 9.8416\n",
      "Epoch 36/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.4425 - val_loss: 3.4431\n",
      "Epoch 37/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5302 - val_loss: 3.3930\n",
      "Epoch 38/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5543 - val_loss: 3.4070\n",
      "Epoch 39/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5314 - val_loss: 3.3447\n",
      "Epoch 40/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5170 - val_loss: 3.4243\n",
      "Epoch 41/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.5093 - val_loss: 3.3836\n",
      "Epoch 42/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.4920 - val_loss: 3.5088\n",
      "Epoch 43/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.4795 - val_loss: 6.2802\n",
      "Epoch 44/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.4257 - val_loss: 3.3775\n",
      "Epoch 45/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.4004 - val_loss: 3.5005\n",
      "Epoch 46/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.3231 - val_loss: 4.2127\n",
      "Epoch 47/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.3087 - val_loss: 3.5725\n",
      "Epoch 48/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.2821 - val_loss: 3.5070\n",
      "Epoch 49/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.2738 - val_loss: 3.4097\n",
      "Epoch 50/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.1725 - val_loss: 3.6273\n",
      "Epoch 51/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 3.1874 - val_loss: 3.7178\n",
      "Epoch 52/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.9675 - val_loss: 3.7046\n",
      "Epoch 53/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.9170 - val_loss: 3.6204\n",
      "Epoch 54/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.9011 - val_loss: 4.2816\n",
      "Epoch 55/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.7417 - val_loss: 3.6331\n",
      "Epoch 56/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.8944 - val_loss: 4.0343\n",
      "Epoch 57/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.7522 - val_loss: 4.5874\n",
      "Epoch 58/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.8868 - val_loss: 3.9464\n",
      "Epoch 59/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.7768 - val_loss: 4.1697\n",
      "Epoch 60/60\n",
      "1331391/1331391 [==============================] - 8s 6us/step - loss: 2.9948 - val_loss: 3.4713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20e29033648>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, target,  batch_size = 4168,\n",
    "          epochs = 60, verbose = 1, \n",
    "          validation_data=(x_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSLE =  1.893043048351508\n"
     ]
    }
   ],
   "source": [
    "print('Train RMSLE = ',rmsle_score(np.expm1(target) , np.expm1(model.predict(x_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570597/570597 [==============================] - 1s 2us/step\n",
      "RMSLE of Test set is  1.8631497456782922\n"
     ]
    }
   ],
   "source": [
    "preds = np.expm1(model.predict(x_test,batch_size = 4168,verbose = 1))\n",
    "print('RMSLE of Test set is ',rmsle_score(np.expm1(target_test).values , preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
